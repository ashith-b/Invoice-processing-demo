import logging

import azure.functions as func
from langchain.chat_models import ChatOpenAI
from langchain import PromptTemplate

from langchain.prompts import (
    ChatPromptTemplate,
    PromptTemplate,
    SystemMessagePromptTemplate,
)
import os
import json
import time
from dotenv import load_dotenv
from azure.storage.blob import BlobServiceClient
import pandas as pd
import io
load_dotenv()

template = '''
System: As your AI assistant, my purpose is to assist you in extracting information from invoices and provide the details in JSON format. Here's how it works:

Example 1:
input_invoice: {input}
output_json : {output}


input : {input_invoice}
output:
'''


def generate_invoice_response(template, invoice_example, processed_json, input_invoice):
    """
    Generates a chat response using the specified template and input data.

    Parameters:
    template (str): Template for formatting the chat prompt.
    invoice_example (str): Input invoice example data.
    processed_json (str): Processed JSON data.
    input_invoice (str): Input invoice information.

    Returns:
    str: Chat response generated by GPT-4 model.
    """
    gpt4_prompt = PromptTemplate(
        template=template,
        input_variables=["input", "output", "input_invoice"]
    )

    system_message_prompt = SystemMessagePromptTemplate(prompt=gpt4_prompt)

    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])

    # Format the chat prompt using the provided input data
    messages = chat_prompt.format_prompt(input=invoice_example, output=processed_json, input_invoice=input_invoice).to_messages()

    # Create a GPT-4 chat instance
    chat = ChatOpenAI(engine="gpt-4-32k", temperature=0)

    # Generate the chat response using the formatted messages
    resp = chat(messages)

    # Return the content of the response
    return resp.content



def download_blob_from_storage(blob_path):
    
    blob_service_client = BlobServiceClient.from_connection_string(os.environ['AZURE_STORAGE_CONNECTION_STRING'])

# Get a client to interact with the specified container
    container_client = blob_service_client.get_container_client(os.environ['BLOB_CONTAINER_NAME'])

    # Get a client to interact with the specified blob
    blob_client = container_client.get_blob_client(blob_path.replace(f"{os.environ['BLOB_CONTAINER_NAME']}/",""))

    # Download the blob's content
    with io.BytesIO() as input_stream:
    # Download the blob to the stream
        downloader = blob_client.download_blob()
        
        # Write the blob's data into the stream
        downloader.readinto(input_stream)
        
        # Seek to the beginning of the stream
        input_stream.seek(0)
        
        # Load the stream data into a pandas DataFrame
        df = pd.read_excel(input_stream)

    json_str = df.apply(lambda x: [x.dropna()], axis=1).to_json(orient='index', date_format='iso')
    return json_str



def main(req: func.HttpRequest) -> func.HttpResponse:
    logging.info('Python HTTP trigger function processed a request.')

    if req.method == "POST":
        # Handle POST request
        try:
            req_body = req.get_json()
            raw_invoice_example = req_body["raw_invoice_example"]
            invoice_example_excel = req_body["excel_example"]
            raw_invoice_input = req_body["raw_invoice_input"]
            excel_json = download_blob_from_storage(invoice_example_excel)

            llmoutput = generate_invoice_response(template,raw_invoice_example,excel_json,raw_invoice_input)
            llm_json = json.loads(llmoutput)

            logging.info(llm_json)
            print(llm_json)
            return func.HttpResponse(
                json.dumps(llm_json),
            #    relevance_scoring,
                mimetype="application/json",
            )

        except ValueError:
            return func.HttpResponse(
                 "Invalid request body",
                 status_code=400
            )
    
    return func.HttpResponse(
                 "Invalid request body",
                 status_code=400
            )

    
